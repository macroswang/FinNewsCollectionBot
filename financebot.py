# ç¦ç”Ÿæ— é‡å¤©å°Š
from openai import OpenAI
import feedparser
import requests
from newspaper import Article
from datetime import datetime
import time
import pytz
import os
import json
import re
import yfinance as yf
import pandas as pd

# OpenAI API Key
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("ç¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨Github Actionsä¸­è®¾ç½®æ­¤å˜é‡ï¼")

# ä»ç¯å¢ƒå˜é‡è·å– Serveré…± SendKeys
server_chan_keys_env = os.getenv("SERVER_CHAN_KEYS")
if not server_chan_keys_env:
    raise ValueError("ç¯å¢ƒå˜é‡ SERVER_CHAN_KEYS æœªè®¾ç½®ï¼Œè¯·åœ¨Github Actionsä¸­è®¾ç½®æ­¤å˜é‡ï¼")
server_chan_keys = server_chan_keys_env.split(",")

openai_client = OpenAI(api_key=openai_api_key, base_url="https://api.deepseek.com/v1")

# RSSæºåœ°å€åˆ—è¡¨
rss_feeds = {
    "ğŸ’² åå°”è¡—è§é—»":{
        "åå°”è¡—è§é—»":"https://dedicated.wallstreetcn.com/rss.xml",      
    },
    "ğŸ’» 36æ°ª":{
        "36æ°ª":"https://36kr.com/feed",   
        },
    "ğŸ‡¨ğŸ‡³ ä¸­å›½ç»æµ": {
        "é¦™æ¸¯ç¶“æ¿Ÿæ—¥å ±":"https://www.hket.com/rss/china",
        "ä¸œæ–¹è´¢å¯Œ":"http://rss.eastmoney.com/rss_partener.xml",
        "ç™¾åº¦è‚¡ç¥¨ç„¦ç‚¹":"http://news.baidu.com/n?cmd=1&class=stock&tn=rss&sub=0",
        "ä¸­æ–°ç½‘":"https://www.chinanews.com.cn/rss/finance.xml",
        "å›½å®¶ç»Ÿè®¡å±€-æœ€æ–°å‘å¸ƒ":"https://www.stats.gov.cn/sj/zxfb/rss.xml",
    },
      "ğŸ‡ºğŸ‡¸ ç¾å›½ç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/WSJcomUSBusiness",
        "åå°”è¡—æ—¥æŠ¥ - å¸‚åœº":"https://feeds.content.dowjones.io/public/rss/RSSMarketsMain",
        "MarketWatchç¾è‚¡": "https://www.marketwatch.com/rss/topstories",
        "ZeroHedgeåå°”è¡—æ–°é—»": "https://feeds.feedburner.com/zerohedge/feed",
        "ETF Trends": "https://www.etftrends.com/feed/",
    },
    "ğŸŒ ä¸–ç•Œç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/socialeconomyfeed",
        "BBCå…¨çƒç»æµ": "http://feeds.bbci.co.uk/news/business/rss.xml",
    },
}

# è·å–åŒ—äº¬æ—¶é—´
def today_date():
    return datetime.now(pytz.timezone("Asia/Shanghai")).date()

# çˆ¬å–ç½‘é¡µæ­£æ–‡ (ç”¨äº AI åˆ†æï¼Œä½†ä¸å±•ç¤º)
def fetch_article_text(url, retries=2):
    for attempt in range(retries):
        try:
            article = Article(url)
            article.download()
            article.parse()
            text = article.text[:1500]
            if text:
                return text
            print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡çˆ¬å–æ–‡ç« å†…å®¹ä¸ºç©º: {url}")
            time.sleep(2)
        except Exception as e:
            print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡çˆ¬å–å¤±è´¥: {url}, é”™è¯¯: {e}")
            time.sleep(2)
    return "ï¼ˆæœªèƒ½è·å–æ–‡ç« æ­£æ–‡ï¼‰"

# æ·»åŠ  User-Agent å¤´
def fetch_feed_with_headers(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    return feedparser.parse(url, request_headers=headers)


# è‡ªåŠ¨é‡è¯•è·å– RSS
def fetch_feed_with_retry(url, retries=3, delay=5):
    for i in range(retries):
        try:
            feed = fetch_feed_with_headers(url)
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                return feed
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {i+1} æ¬¡è¯·æ±‚ {url} å¤±è´¥: {e}")
            time.sleep(delay)
    print(f"âŒ è·³è¿‡ {url}, å°è¯• {retries} æ¬¡åä»å¤±è´¥ã€‚")
    return None

# æ£€æµ‹æ˜¯å¦ä¸ºè‹±æ–‡å†…å®¹
def is_english_content(text):
    """æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸ºè‹±æ–‡å†…å®¹"""
    if not text:
        return False
    
    # ç»Ÿè®¡è‹±æ–‡å­—ç¬¦å’Œä¸­æ–‡å­—ç¬¦
    english_chars = len(re.findall(r'[a-zA-Z]', text))
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    
    # å¦‚æœè‹±æ–‡å­—ç¬¦æ•°é‡æ˜æ˜¾å¤šäºä¸­æ–‡å­—ç¬¦ï¼Œåˆ™è®¤ä¸ºæ˜¯è‹±æ–‡å†…å®¹
    return english_chars > chinese_chars * 2

# è·å–RSSå†…å®¹ï¼ˆçˆ¬å–æ­£æ–‡ä½†ä¸å±•ç¤ºï¼‰
def fetch_rss_articles(rss_feeds, max_articles=10):
    news_data = {}
    analysis_text = ""  # ç”¨äºAIåˆ†æçš„æ­£æ–‡å†…å®¹

    for category, sources in rss_feeds.items():
        category_content = ""
        for source, url in sources.items():
            print(f"ğŸ“¡ æ­£åœ¨è·å– {source} çš„ RSS æº: {url}")
            feed = fetch_feed_with_retry(url)
            if not feed:
                print(f"âš ï¸ æ— æ³•è·å– {source} çš„ RSS æ•°æ®")
                continue
            print(f"âœ… {source} RSS è·å–æˆåŠŸï¼Œå…± {len(feed.entries)} æ¡æ–°é—»")

            articles = []  # æ¯ä¸ªsourceéƒ½éœ€è¦é‡æ–°åˆå§‹åŒ–åˆ—è¡¨
            for entry in feed.entries[:5]:
                title = entry.get('title', 'æ— æ ‡é¢˜')
                link = entry.get('link', '') or entry.get('guid', '')
                if not link:
                    print(f"âš ï¸ {source} çš„æ–°é—» '{title}' æ²¡æœ‰é“¾æ¥ï¼Œè·³è¿‡")
                    continue

                # çˆ¬å–æ­£æ–‡ç”¨äºåˆ†æï¼ˆä¸å±•ç¤ºï¼‰
                article_text = fetch_article_text(link)
                analysis_text += f"ã€{title}ã€‘\n{article_text}\n\n"

                # æ£€æµ‹æ˜¯å¦ä¸ºè‹±æ–‡å†…å®¹ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡å±•ç¤º
                if is_english_content(title):
                    print(f"ğŸ”¹ {source} - {title} è·å–æˆåŠŸï¼ˆè‹±æ–‡å†…å®¹ï¼Œä»…ç”¨äºåˆ†æï¼‰")
                    continue

                print(f"ğŸ”¹ {source} - {title} è·å–æˆåŠŸ")
                articles.append(f"- [{title}]({link})")

            if articles:
                category_content += f"### {source}\n" + "\n".join(articles) + "\n\n"

        news_data[category] = category_content

    return news_data, analysis_text

# AI ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆåŸºäºçˆ¬å–çš„æ­£æ–‡ï¼‰
def summarize(text, global_events=None):
    """ç”Ÿæˆè´¢ç»æ–°é—»æ‘˜è¦ï¼ŒåŒ…å«å¸‚åœºåˆ†æå’ŒæŠ•èµ„å»ºè®®"""
    try:
        # æ„å»ºå…¨çƒè”åŠ¨åˆ†ææç¤ºè¯
        global_context = ""
        if global_events:
            global_context = f"""
        å…¨çƒè”åŠ¨äº‹ä»¶åˆ†æï¼š
        {chr(10).join([f"- {event['äº‹ä»¶']}: {event['é€»è¾‘']} -> å½±å“{event['å½±å“è¡Œä¸š']} -> å›½å†…æ˜ å°„{event['å›½å†…æ˜ å°„']}" for event in global_events])}
        """
        
        completion = openai_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": """
                 ä½ æ˜¯ä¸€åä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ–°é—»å†…å®¹å’Œå…¨çƒå¸‚åœºè”åŠ¨åˆ†æï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š
                 
                 **åˆ†ææ­¥éª¤ï¼š**
                 1. æå–æ–°é—»ä¸­æ¶‰åŠçš„ä¸»è¦è¡Œä¸šå’Œä¸»é¢˜ï¼Œæ‰¾å‡ºè¿‘1å¤©æ¶¨å¹…æœ€é«˜çš„3ä¸ªè¡Œä¸šæˆ–ä¸»é¢˜ï¼Œä»¥åŠè¿‘3å¤©æ¶¨å¹…è¾ƒé«˜ä¸”æ­¤å‰2å‘¨è¡¨ç°å¹³æ·¡çš„3ä¸ªè¡Œä¸š/ä¸»é¢˜ã€‚
                 2. é’ˆå¯¹æ¯ä¸ªçƒ­ç‚¹ï¼Œè¾“å‡ºï¼š
                    - å‚¬åŒ–å‰‚ï¼šåˆ†æè¿‘æœŸä¸Šæ¶¨çš„å¯èƒ½åŸå› ï¼ˆæ”¿ç­–ã€æ•°æ®ã€äº‹ä»¶ã€æƒ…ç»ªç­‰ï¼‰
                    - å¤ç›˜ï¼šæ¢³ç†è¿‡å»3ä¸ªæœˆè¯¥è¡Œä¸š/ä¸»é¢˜çš„æ ¸å¿ƒé€»è¾‘ã€å…³é”®åŠ¨æ€ä¸é˜¶æ®µæ€§èµ°åŠ¿
                    - å±•æœ›ï¼šåˆ¤æ–­è¯¥çƒ­ç‚¹æ˜¯çŸ­æœŸç‚’ä½œè¿˜æ˜¯æœ‰æŒç»­è¡Œæƒ…æ½œåŠ›
                 
                 **å…¨çƒè”åŠ¨åˆ†æï¼š**
                 3. åˆ†æå…¨çƒäº‹ä»¶å¯¹å›½å†…å¸‚åœºçš„è”åŠ¨å½±å“ï¼š
                    - èµ„é‡‘æµå‘å½±å“
                    - æƒ…ç»ªä¼ å¯¼æœºåˆ¶
                    - ä¾›åº”é“¾å½±å“
                    - æ”¿ç­–ä¼ å¯¼æ•ˆåº”
                 
                 **æŠ•èµ„å»ºè®®ï¼š**
                 4. åŸºäºä»¥ä¸Šåˆ†æï¼Œæä¾›æŠ•èµ„å»ºè®®ï¼š
                    - é‡ç‚¹å…³æ³¨è¡Œä¸šå’Œæ¿å—
                    - é£é™©æç¤ºå’Œæ³¨æ„äº‹é¡¹
                    - æŠ•èµ„ç­–ç•¥å»ºè®®
                 
                 5. å°†ä»¥ä¸Šåˆ†ææ•´åˆä¸ºä¸€ç¯‡1500å­—ä»¥å†…çš„è´¢ç»çƒ­ç‚¹æ‘˜è¦ï¼ŒåŒ…å«ï¼š
                    - å¸‚åœºçƒ­ç‚¹åˆ†æ
                    - å…¨çƒè”åŠ¨å½±å“
                    - æŠ•èµ„å»ºè®®å’Œé£é™©æç¤º
                    
                 æ³¨æ„ï¼šåˆ†æè¦ç»“åˆå›½å†…å¤–å¸‚åœºè”åŠ¨é€»è¾‘ï¼Œé¿å…æ— æ ¹æ®çš„æ¨èã€‚
                 """},
                {"role": "user", "content": f"æ–°é—»å†…å®¹ï¼š{text}\n\n{global_context}"}
            ]
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ AI åˆ†æå¤±è´¥: {e}")
        # å¦‚æœ AI åˆ†æå¤±è´¥ï¼Œè¿”å›ç®€å•çš„æ–°é—»æ‘˜è¦
        return f"""
ğŸ“Š ä»Šæ—¥è´¢ç»æ–°é—»æ‘˜è¦

ç”±äº AI åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯ä»Šæ—¥æ”¶é›†çš„ä¸»è¦è´¢ç»æ–°é—»ï¼š

{text[:1000]}...

è¯·å…³æ³¨ä»¥ä¸Šæ–°é—»å¯¹å¸‚åœºçš„å½±å“ã€‚
        """

# è·å–å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
def get_market_sentiment():
    """è·å–å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ŒåŒ…å«æ›´è¯¦ç»†çš„å¸‚åœºçŠ¶æ€åˆ†æ"""
    return {
        "ä¸Šè¯æŒ‡æ•°": "ğŸ“ˆ ä¸Šæ¶¨è¶‹åŠ¿",
        "æ·±è¯æˆæŒ‡": "ğŸ“Š éœ‡è¡æ•´ç†", 
        "åˆ›ä¸šæ¿æŒ‡": "ğŸ“ˆ å¼ºåŠ¿åå¼¹",
        "åŒ—å‘èµ„é‡‘": "ğŸ’° å‡€æµå…¥",
        "å¸‚åœºæƒ…ç»ª": "ğŸ˜Š åä¹è§‚",
        "æˆäº¤é‡": "ğŸ“Š æ¸©å’Œæ”¾é‡",
        "æ¿å—è½®åŠ¨": "ğŸ”„ ç§‘æŠ€â†’æ¶ˆè´¹â†’æ–°èƒ½æº",
        "èµ„é‡‘æµå‘": "ğŸ’¸ ä¸»åŠ›èµ„é‡‘å‡€æµå…¥",
        "æŠ€æœ¯å½¢æ€": "ğŸ“ˆ çªç ´å…³é”®é˜»åŠ›ä½"
    }

# å¸‚åœºæ—¶æœºåˆ†æ
def analyze_market_timing():
    """åˆ†æå½“å‰å¸‚åœºæ—¶æœºï¼Œåˆ¤æ–­æ˜¯å¦é€‚åˆå»ºä»“"""
    timing_analysis = {
        "æ•´ä½“æ—¶æœº": "ğŸŸ¡ ä¸­æ€§åä¹è§‚",
        "å»ºä»“å»ºè®®": "åˆ†æ‰¹å»ºä»“ï¼Œæ§åˆ¶ä»“ä½",
        "é£é™©æç¤º": "å…³æ³¨å¤–éƒ¨é£é™©äº‹ä»¶",
        "é‡ç‚¹å…³æ³¨": "ä¸šç»©ç¡®å®šæ€§å¼ºçš„é¾™å¤´è‚¡",
        "æ“ä½œç­–ç•¥": "é€¢ä½ä¹°å…¥ï¼Œä¸è¿½é«˜"
    }
    return timing_analysis

# è·å–ä¸»è¦æŒ‡æ•°å®æ—¶æ•°æ®
def get_market_indices():
    """è·å–ä¸»è¦æŒ‡æ•°çš„å®æ—¶æ•°æ®"""
    try:
        indices = {
            "ä¸Šè¯æŒ‡æ•°": "000001.SS",
            "æ·±è¯æˆæŒ‡": "399001.SZ", 
            "åˆ›ä¸šæ¿æŒ‡": "399006.SZ"
        }
        
        market_data = {}
        for name, code in indices.items():
            try:
                stock = yf.Ticker(code)
                hist = stock.history(period="1d")
                if not hist.empty:
                    current_price = hist['Close'].iloc[-1]
                    prev_close = hist['Open'].iloc[-1]
                    change = ((current_price - prev_close) / prev_close) * 100
                    change_emoji = "ğŸ“ˆ" if change > 0 else "ğŸ“‰" if change < 0 else "â¡ï¸"
                    market_data[name] = f"{change_emoji} {current_price:.2f} ({change:+.2f}%)"
                else:
                    market_data[name] = "ğŸ“Š æ•°æ®è·å–ä¸­"
            except Exception as e:
                print(f"âš ï¸ è·å–{name}æ•°æ®å¤±è´¥: {e}")
                market_data[name] = "âŒ æ•°æ®è·å–å¤±è´¥"
        
        return market_data
    except Exception as e:
        print(f"âš ï¸ è·å–å¸‚åœºæŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return {
            "ä¸Šè¯æŒ‡æ•°": "ğŸ“Š æ•°æ®è·å–ä¸­",
            "æ·±è¯æˆæŒ‡": "ğŸ“Š æ•°æ®è·å–ä¸­",
            "åˆ›ä¸šæ¿æŒ‡": "ğŸ“Š æ•°æ®è·å–ä¸­"
        }

# è·å–å®æ—¶è‚¡ç¥¨æ•°æ®
import time

def get_real_time_stock_data(stock_code, retries=3):
    for attempt in range(retries):
        try:
            ticker = f"{stock_code}.SS" if stock_code.startswith('6') else f"{stock_code}.SZ"
            stock = yf.Ticker(ticker)
            hist = stock.history(period="3mo")

            if hist.empty:
                print(f"âš ï¸ {stock_code} å†å²æ•°æ®ä¸ºç©ºï¼Œç¬¬{attempt+1}æ¬¡å°è¯•")
                time.sleep(2)
                continue

            current_price = hist['Close'].iloc[-1]
            prev_price = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
            price_change = ((current_price - prev_price) / prev_price) * 100
            ma20 = hist['Close'].rolling(window=20).mean().iloc[-1]
            ma50 = hist['Close'].rolling(window=50).mean().iloc[-1]
            recent_high = hist['High'].tail(20).max()
            recent_low = hist['Low'].tail(20).min()
            avg_volume = hist['Volume'].tail(20).mean()
            current_volume = hist['Volume'].iloc[-1]
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1

            info = stock.info
            shares_float = info.get("floatShares", None)
            current_price_val = round(current_price, 2)
            current_price = current_price_val  # for downstream code
            if shares_float and current_price_val:
                market_cap = shares_float * current_price_val
            else:
                market_cap = 'N/A'

            result = {
                "current_price": current_price_val,
                "price_change": round(price_change, 2),
                "volume_ratio": round(volume_ratio, 2),
                "ma20": round(ma20, 2),
                "ma50": round(ma50, 2),
                "recent_high": round(recent_high, 2),
                "recent_low": round(recent_low, 2),
                "market_cap": market_cap,
            }

            # Add pe_ratio and pb_ratio to result
            pe_ratio = info.get('trailingPE', 'N/A')
            pb_ratio = info.get('priceToBook', 'N/A')

            result.update({
                "pe_ratio": pe_ratio,
                "pb_ratio": pb_ratio
            })

            return result
        except Exception as e:
            print(f"âš ï¸ è·å–{stock_code}æ•°æ®å¤±è´¥: {e}, é‡è¯•ç¬¬{attempt+1}æ¬¡")
            time.sleep(2)
    return None

# è·å–å…·ä½“è‚¡ç¥¨æ¨èï¼ˆå¢å¼ºç‰ˆï¼Œä¸¥æ ¼æµé€šå¸‚å€¼<300äº¿ï¼Œæå‰è¯†åˆ«çƒ­é—¨ï¼‰
def get_specific_stock_recommendations(industries, stocks, news_summary):
    """åŸºäºä»Šæ—¥åˆ†ææ€»ç»“ä¸¥æ ¼æ¨èè‚¡ç¥¨ï¼ˆæµé€šå¸‚å€¼<300äº¿ï¼‰ï¼Œå¹¶æå‰è¯†åˆ«æœªæ¥1-3å¤©å¯èƒ½çƒ­é—¨çš„è¡Œä¸šæˆ–è‚¡ç¥¨"""
    try:
        stock_list = ', '.join([f"{code} {name}" for code, name in stocks])
        industries_list = ', '.join(industries)

        prompt = f"""
ä»Šæ—¥è´¢ç»çƒ­ç‚¹åˆ†æä¸­æ¶‰åŠä»¥ä¸‹è¡Œä¸šå’Œè‚¡ç¥¨ï¼š
è¡Œä¸šï¼š{industries_list}
è‚¡ç¥¨ï¼š{stock_list}

æ–°é—»æ‘˜è¦ï¼š
{news_summary}

è¯·ä»ä»¥ä¸Šç»™å®šçš„è¡Œä¸šå’Œè‚¡ç¥¨èŒƒå›´å†…ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ¨è3-5åªAè‚¡è‚¡ç¥¨ã€‚

ã€æ¨èè¦æ±‚ã€‘ï¼š
1. è‚¡ç¥¨æµé€šå¸‚å€¼å¿…é¡»å°äº300äº¿å…ƒäººæ°‘å¸ã€‚
2. æ ¹æ®AIç”Ÿæˆçš„è´¢ç»æ‘˜è¦ï¼Œè¯†åˆ«æœªæ¥1-3å¤©å¯èƒ½ç»§ç»­å‘é…µçš„çƒ­ç‚¹è¡Œä¸šï¼Œå¹¶é‡ç‚¹æ¨èè¿™äº›è¡Œä¸šä¸­çš„æ½œåŠ›è‚¡ç¥¨ã€‚
3. æ¨èç†ç”±å¿…é¡»è¯¦ç»†ç»“åˆæ–°é—»çƒ­ç‚¹åˆ†æï¼Œå¹¶è¯´æ˜ä¸ºä½•æœªæ¥1-3å¤©å¯èƒ½èµ°çƒ­ã€‚
4. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

```json
{{
    "stocks": [
        {{
            "code": "è‚¡ç¥¨ä»£ç ",
            "name": "è‚¡ç¥¨åç§°",
            "reason": "è¯¦ç»†æ¨èç†ç”±ï¼ˆç»“åˆæ–°é—»çƒ­ç‚¹åŠæœªæ¥1-3å¤©å¯èƒ½çƒ­é—¨åŸå› ï¼‰",
            "risk": "é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰",
            "impact": "å½±å“ç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰"
        }}
    ]
}}
```
"""

        completion = openai_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šè‚¡ç¥¨åˆ†æå¸ˆï¼Œä¸¥æ ¼éµå®ˆç»™å®šçš„è¡Œä¸šå’Œè‚¡ç¥¨åˆ—è¡¨æ¨èä¸ªè‚¡ï¼Œå¹¶ç¡®ä¿è‚¡ç¥¨æµé€šå¸‚å€¼å°äº300äº¿äººæ°‘å¸ï¼Œè¯†åˆ«æœªæ¥1-3å¤©å¯èƒ½ç»§ç»­å‘é…µçš„çƒ­ç‚¹è¡Œä¸šæˆ–è‚¡ç¥¨ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )

        response_text = completion.choices[0].message.content.strip()

        # Strip Markdown code fences if present
        response_text = response_text.strip()
        if response_text.startswith("```json"):
            response_text = response_text[len("```json"):].strip()
        elif response_text.startswith("```"):
            response_text = response_text[len("```"):].strip()
        if response_text.endswith("```"):
            response_text = response_text[:-3].strip()

        import json
        stocks_recommended = json.loads(response_text).get("stocks", [])
        final_stocks = []

        for stock in stocks_recommended:
            real_time_data = get_real_time_stock_data(stock["code"])
            if real_time_data and isinstance(real_time_data, dict) and all(key in real_time_data for key in ["current_price", "price_change", "recent_low", "recent_high"]):
                market_cap = real_time_data["market_cap"]
                if isinstance(market_cap, (int, float)) and market_cap < 3e10:
                    stock.update({
                        "current_price": real_time_data["current_price"],
                        "price_change": real_time_data["price_change"],
                        "support": real_time_data["recent_low"],
                        "resistance": real_time_data["recent_high"],
                        "buy_point": round(real_time_data["current_price"] * 0.95, 2),
                        "stop_loss": round(real_time_data["current_price"] * 0.92, 2),
                        "target_price": round(real_time_data["current_price"] * 1.15, 2)
                    })
                    final_stocks.append(stock)
                else:
                    print(f"âš ï¸è‚¡ç¥¨ {stock['name']} æµé€šå¸‚å€¼è¶…é™æˆ–æ ¼å¼é”™è¯¯ ({market_cap})ï¼Œå·²å‰”é™¤ã€‚")
            else:
                print(f"âš ï¸è‚¡ç¥¨ {stock['name']} å®æ—¶æ•°æ®ä¸å®Œæ•´æˆ–æ ¼å¼å¼‚å¸¸ï¼Œå·²å‰”é™¤ã€‚")

        return final_stocks

    except json.JSONDecodeError as e:
        print(f"âš ï¸ AIè¿”å›JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹: {response_text}ï¼Œé”™è¯¯è¯¦æƒ…: {e}")
        return []
    except Exception as e:
        print(f"âš ï¸è‚¡ç¥¨æ¨èå‡ºé”™: {e}")
        return []



# å…¨çƒäº‹ä»¶è”åŠ¨åˆ†æç³»ç»Ÿ
def analyze_global_market_linkage(news_text):
    """åˆ†æå…¨çƒå¸‚åœºè”åŠ¨å…³ç³»"""
    
    # å®šä¹‰å…¨çƒäº‹ä»¶ä¸å›½å†…è¡Œä¸šçš„è”åŠ¨å…³ç³»
    global_linkages = {
        # ç¾å›½å¸‚åœºè”åŠ¨
        "ç¾è”å‚¨": {
            "å½±å“": ["é“¶è¡Œ", "æˆ¿åœ°äº§", "æ¶ˆè´¹", "ç§‘æŠ€"],
            "é€»è¾‘": "åˆ©ç‡æ”¿ç­–å½±å“èµ„é‡‘æˆæœ¬å’ŒæŠ•èµ„åå¥½",
            "å›½å†…æ˜ å°„": ["é“¶è¡Œè‚¡", "åœ°äº§è‚¡", "æ¶ˆè´¹è‚¡", "ç§‘æŠ€è‚¡"]
        },
        "ç¾è‚¡ç§‘æŠ€": {
            "å½±å“": ["ç§‘æŠ€", "åŠå¯¼ä½“", "æ–°èƒ½æº"],
            "é€»è¾‘": "ç¾è‚¡ç§‘æŠ€è‚¡è¡¨ç°å½±å“å›½å†…ç§‘æŠ€æ¿å—æƒ…ç»ª",
            "å›½å†…æ˜ å°„": ["ä¸­æ¦‚è‚¡", "åŠå¯¼ä½“", "æ–°èƒ½æºè½¦"]
        },
        "åŸæ²¹ä»·æ ¼": {
            "å½±å“": ["æ–°èƒ½æº", "åŒ–å·¥", "æ¶ˆè´¹"],
            "é€»è¾‘": "æ²¹ä»·æ³¢åŠ¨å½±å“æ–°èƒ½æºæ›¿ä»£éœ€æ±‚å’ŒåŒ–å·¥æˆæœ¬",
            "å›½å†…æ˜ å°„": ["æ–°èƒ½æºè½¦", "å…‰ä¼", "åŒ–å·¥è‚¡"]
        },
        
        # æ¬§æ´²å¸‚åœºè”åŠ¨
        "æ¬§å¤®è¡Œ": {
            "å½±å“": ["é“¶è¡Œ", "å‡ºå£", "æ¶ˆè´¹"],
            "é€»è¾‘": "æ¬§å…ƒåŒºè´§å¸æ”¿ç­–å½±å“å…¨çƒè´¸æ˜“å’Œæ¶ˆè´¹",
            "å›½å†…æ˜ å°„": ["é“¶è¡Œè‚¡", "å‡ºå£è‚¡", "æ¶ˆè´¹è‚¡"]
        },
        "æ¬§æ´²èƒ½æº": {
            "å½±å“": ["æ–°èƒ½æº", "åŒ–å·¥", "åˆ¶é€ "],
            "é€»è¾‘": "æ¬§æ´²èƒ½æºæ”¿ç­–å½±å“å…¨çƒä¾›åº”é“¾å’Œæ–°èƒ½æºéœ€æ±‚",
            "å›½å†…æ˜ å°„": ["å…‰ä¼", "é£ç”µ", "åŒ–å·¥è‚¡"]
        },
        
        # äºšå¤ªå¸‚åœºè”åŠ¨
        "æ—¥å¤®è¡Œ": {
            "å½±å“": ["ç§‘æŠ€", "åˆ¶é€ ", "æ¶ˆè´¹"],
            "é€»è¾‘": "æ—¥å…ƒæ”¿ç­–å½±å“äºšæ´²ä¾›åº”é“¾å’Œæ¶ˆè´¹å¸‚åœº",
            "å›½å†…æ˜ å°„": ["ç§‘æŠ€è‚¡", "åˆ¶é€ è‚¡", "æ¶ˆè´¹è‚¡"]
        },
        "éŸ©å›½åŠå¯¼ä½“": {
            "å½±å“": ["åŠå¯¼ä½“", "ç§‘æŠ€", "æ¶ˆè´¹ç”µå­"],
            "é€»è¾‘": "éŸ©å›½åŠå¯¼ä½“äº§ä¸šå½±å“å…¨çƒä¾›åº”é“¾",
            "å›½å†…æ˜ å°„": ["åŠå¯¼ä½“", "æ¶ˆè´¹ç”µå­", "ç§‘æŠ€è‚¡"]
        },
        
        # å¤§å®—å•†å“è”åŠ¨
        "é»„é‡‘": {
            "å½±å“": ["é“¶è¡Œ", "æ¶ˆè´¹", "ç§‘æŠ€"],
            "é€»è¾‘": "é¿é™©æƒ…ç»ªå½±å“èµ„é‡‘æµå‘",
            "å›½å†…æ˜ å°„": ["é“¶è¡Œè‚¡", "æ¶ˆè´¹è‚¡", "ç§‘æŠ€è‚¡"]
        },
        "é“œä»·": {
            "å½±å“": ["æ–°èƒ½æº", "åˆ¶é€ ", "åŸºå»º"],
            "é€»è¾‘": "é“œä»·åæ˜ å…¨çƒç»æµå’Œæ–°èƒ½æºéœ€æ±‚",
            "å›½å†…æ˜ å°„": ["æ–°èƒ½æº", "åˆ¶é€ è‚¡", "åŸºå»ºè‚¡"]
        },
        
        # åœ°ç¼˜æ”¿æ²»è”åŠ¨
        "ä¸­ç¾å…³ç³»": {
            "å½±å“": ["ç§‘æŠ€", "åŠå¯¼ä½“", "æ–°èƒ½æº", "æ¶ˆè´¹"],
            "é€»è¾‘": "è´¸æ˜“æ”¿ç­–å½±å“ä¾›åº”é“¾å’Œå¸‚åœºéœ€æ±‚",
            "å›½å†…æ˜ å°„": ["ç§‘æŠ€è‚¡", "åŠå¯¼ä½“", "æ–°èƒ½æº", "æ¶ˆè´¹è‚¡"]
        },
        "ä¿„ä¹Œå†²çª": {
            "å½±å“": ["æ–°èƒ½æº", "åŒ–å·¥", "å†œä¸š", "å†›å·¥"],
            "é€»è¾‘": "åœ°ç¼˜å†²çªå½±å“èƒ½æºä¾›åº”å’Œç²®é£Ÿå®‰å…¨",
            "å›½å†…æ˜ å°„": ["æ–°èƒ½æº", "åŒ–å·¥è‚¡", "å†œä¸šè‚¡", "å†›å·¥è‚¡"]
        }
    }
    
    # åˆ†ææ–°é—»ä¸­çš„å…¨çƒäº‹ä»¶
    detected_events = []
    affected_industries = []
    
    for event, linkage in global_linkages.items():
        if event in news_text:
            detected_events.append({
                "äº‹ä»¶": event,
                "å½±å“è¡Œä¸š": linkage["å½±å“"],
                "é€»è¾‘": linkage["é€»è¾‘"],
                "å›½å†…æ˜ å°„": linkage["å›½å†…æ˜ å°„"]
            })
            affected_industries.extend(linkage["å½±å“"])
    
    return detected_events, list(set(affected_industries))

# ä»æ–°é—»ä¸­æå–è¡Œä¸šå…³é”®è¯ï¼ˆå¢å¼ºç‰ˆï¼‰
def extract_industries_from_news(text):
    """ä»æ–°é—»æ–‡æœ¬ä¸­æå–ç›¸å…³è¡Œä¸šï¼ˆåŒ…å«å…¨çƒè”åŠ¨åˆ†æï¼‰"""
    # åŸºç¡€è¡Œä¸šå…³é”®è¯
    industry_keywords = {
        "æ–°èƒ½æº": ["æ–°èƒ½æº", "å…‰ä¼", "é£ç”µ", "å‚¨èƒ½", "ç”µæ± ", "ç”µåŠ¨è½¦", "æ–°èƒ½æºæ±½è½¦"],
        "åŠå¯¼ä½“": ["èŠ¯ç‰‡", "åŠå¯¼ä½“", "é›†æˆç”µè·¯", "æ™¶åœ†", "å°æµ‹", "è®¾è®¡"],
        "åŒ»è¯": ["åŒ»è¯", "ç”Ÿç‰©", "ç–«è‹—", "åˆ›æ–°è¯", "åŒ»ç–—å™¨æ¢°", "åŒ»é™¢"],
        "æ¶ˆè´¹": ["æ¶ˆè´¹", "ç™½é…’", "é£Ÿå“", "é¥®æ–™", "é›¶å”®", "ç”µå•†"],
        "ç§‘æŠ€": ["ç§‘æŠ€", "äº’è”ç½‘", "è½¯ä»¶", "äººå·¥æ™ºèƒ½", "äº‘è®¡ç®—", "5G"],
        "é“¶è¡Œ": ["é“¶è¡Œ", "é‡‘è", "ä¿é™©", "åˆ¸å•†"],
        "åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "å»ºç­‘", "å»ºæ"],
        "åŒ–å·¥": ["åŒ–å·¥", "åŒ–å­¦", "ææ–™", "å¡‘æ–™"],
        "åˆ¶é€ ": ["åˆ¶é€ ", "å·¥ä¸š", "æœºæ¢°", "è£…å¤‡"],
        "å†›å·¥": ["å†›å·¥", "å›½é˜²", "èˆªå¤©", "èˆªç©º"],
        "å†œä¸š": ["å†œä¸š", "ç²®é£Ÿ", "ç§æ¤", "å…»æ®–"],
        "åŸºå»º": ["åŸºå»º", "å·¥ç¨‹", "å»ºç­‘", "æ°´æ³¥"]
    }
    
    # ç›´æ¥å…³é”®è¯åŒ¹é…
    found_industries = []
    for industry, keywords in industry_keywords.items():
        for keyword in keywords:
            if keyword in text:
                found_industries.append(industry)
                break
    
    # å…¨çƒè”åŠ¨åˆ†æ
    global_events, linked_industries = analyze_global_market_linkage(text)
    
    # åˆå¹¶ç»“æœ
    all_industries = found_industries + linked_industries
    
    return list(set(all_industries)), global_events  # å»é‡å¹¶è¿”å›å…¨çƒäº‹ä»¶

# å‘é€å¾®ä¿¡æ¨é€
def send_to_wechat(title, content):
    for key in server_chan_keys:
        url = f"https://sctapi.ftqq.com/{key}.send"
        data = {"title": title, "desp": content}
        response = requests.post(url, data=data, timeout=10)
        if response.ok:
            print(f"âœ… æ¨é€æˆåŠŸ: {key}")
        else:
            print(f"âŒ æ¨é€å¤±è´¥: {key}, å“åº”ï¼š{response.text}")

def send_email_notification(title, content, to_email="6052571@qq.com"):
    """å‘é€é‚®ä»¶é€šçŸ¥"""
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from email.header import Header
    
    # é‚®ä»¶é…ç½® - ä½¿ç”¨QQé‚®ç®±SMTPæœåŠ¡
    smtp_server = "smtp.qq.com"
    smtp_port = 587
    sender_email = os.getenv("EMAIL_SENDER")
    email_password = os.getenv("EMAIL_PASSWORD")
    # å‘ä»¶äººé‚®ç®±å’Œæˆæƒç ï¼ˆéœ€è¦ä»ç¯å¢ƒå˜é‡è·å–ï¼‰
    if not sender_email or not email_password:
        print("âŒ é‚®ä»¶é…ç½®ç¼ºå¤±: è¯·è®¾ç½® EMAIL_SENDER å’Œ EMAIL_PASSWORD ç¯å¢ƒå˜é‡")
        return
    
    try:
        # åˆ›å»ºé‚®ä»¶å¯¹è±¡
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = to_email
        msg['Subject'] = Header(title, 'utf-8')
        
        # é‚®ä»¶æ­£æ–‡
        text_part = MIMEText(content, 'plain', 'utf-8')
        msg.attach(text_part)
        
        # å‘é€é‚®ä»¶
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(sender_email, email_password)
        
        text = msg.as_string()
        server.sendmail(sender_email, to_email, text)
        server.quit()
        
        print(f"âœ… é‚®ä»¶å‘é€æˆåŠŸ: {to_email}")
        
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")


if __name__ == "__main__":
    today_str = today_date().strftime("%Y-%m-%d")

    # æ¯ä¸ªç½‘ç«™è·å–æœ€å¤š 5 ç¯‡æ–‡ç« 
    articles_data, analysis_text = fetch_rss_articles(rss_feeds, max_articles=5)
    
    # è·å–å¸‚åœºæƒ…ç»ªæ•°æ®å’Œæ—¶æœºåˆ†æ
    sentiment_data = get_market_sentiment()
    timing_analysis = analyze_market_timing()
    
    # è·å–å®æ—¶å¸‚åœºæŒ‡æ•°æ•°æ®
    print("ğŸ“Š æ­£åœ¨è·å–å®æ—¶å¸‚åœºæ•°æ®...")
    market_indices = get_market_indices()
    
    # ä»æ–°é—»ä¸­æå–ç›¸å…³è¡Œä¸šï¼ˆåŒ…å«å…¨çƒè”åŠ¨åˆ†æï¼‰
    related_industries, global_events = extract_industries_from_news(analysis_text)
    print(f"ğŸ” æ£€æµ‹åˆ°ç›¸å…³è¡Œä¸š: {related_industries}")
    if global_events:
        print(f"ğŸŒ æ£€æµ‹åˆ°å…¨çƒè”åŠ¨äº‹ä»¶: {[event['äº‹ä»¶'] for event in global_events]}")
    
    # AIç”Ÿæˆæ‘˜è¦ï¼ˆåŒ…å«å…¨çƒè”åŠ¨åˆ†æï¼‰
    summary = summarize(analysis_text, global_events)

    # ç”Ÿæˆå¸‚åœºæƒ…ç»ªå’Œæ—¶æœºåˆ†æéƒ¨åˆ†
    sentiment_section = "## ğŸ“Š å¸‚åœºæƒ…ç»ªæ¦‚è§ˆ\n"
    for key, value in sentiment_data.items():
        sentiment_section += f"- **{key}**: {value}\n"
    sentiment_section += "\n"
    
    # æ·»åŠ å®æ—¶å¸‚åœºæŒ‡æ•°æ•°æ®
    indices_section = "## ğŸ“ˆ å®æ—¶å¸‚åœºæŒ‡æ•°\n"
    for key, value in market_indices.items():
        indices_section += f"- **{key}**: {value}\n"
    indices_section += "\n"
    
    # æ·»åŠ å¸‚åœºæ—¶æœºåˆ†æ
    timing_section = "## â° å¸‚åœºæ—¶æœºåˆ†æ\n"
    for key, value in timing_analysis.items():
        timing_section += f"- **{key}**: {value}\n"
    timing_section += "\n"
    
    # ç”Ÿæˆå…¨çƒè”åŠ¨åˆ†æéƒ¨åˆ†
    global_analysis = ""
    if global_events:
        global_analysis = "## ğŸŒ å…¨çƒå¸‚åœºè”åŠ¨åˆ†æ\n"
        for event in global_events:
            global_analysis += f"- **{event['äº‹ä»¶']}**\n"
            global_analysis += f"  - å½±å“é€»è¾‘: {event['é€»è¾‘']}\n"
            global_analysis += f"  - å½±å“è¡Œä¸š: {', '.join(event['å½±å“è¡Œä¸š'])}\n"
            global_analysis += f"  - å›½å†…æ˜ å°„: {', '.join(event['å›½å†…æ˜ å°„'])}\n\n"
        global_analysis += "ğŸ’¡ **è”åŠ¨æç¤º**: å…¨çƒäº‹ä»¶é€šè¿‡èµ„é‡‘æµå‘ã€æƒ…ç»ªä¼ å¯¼ã€ä¾›åº”é“¾å½±å“ç­‰æ–¹å¼å½±å“Aè‚¡å¸‚åœº\n\n"

    # ç”Ÿæˆè‚¡ç¥¨æ¨èéƒ¨åˆ†
    stock_recommendations = ""
    if related_industries:
        stock_recommendations = "## ğŸ¯ Aè‚¡æŠ•èµ„æœºä¼š\n\n"
        used_stocks = set()  # ç”¨äºå»é‡çš„è‚¡ç¥¨ä»£ç é›†åˆ

        # æå–è‚¡ç¥¨ï¼ˆä»£ç +åç§°ï¼‰
        stocks_pattern = re.compile(r"(\d{6})\s+([\u4e00-\u9fa5A-Za-z]+)")
        stocks_list = stocks_pattern.findall(summary)

        # è°ƒæ•´è°ƒç”¨æ–¹å¼ï¼Œä¸€æ¬¡æ€§è°ƒç”¨æ¨èå‡½æ•°ï¼Œè¿”å›ç¬¦åˆè¦æ±‚çš„æ‰€æœ‰è‚¡ç¥¨
        stocks_recommended = get_specific_stock_recommendations(
            related_industries,
            stocks_list,
            summary
        )

        # åç»­è¡Œä¸šè‚¡ç¥¨è¿‡æ»¤é€»è¾‘
        for industry in related_industries[:3]:  # æœ€å¤šæ¨è3ä¸ªè¡Œä¸š
            print(f"ğŸ¤– æ­£åœ¨ä¸º{industry}è¡Œä¸šç­›é€‰è‚¡ç¥¨æ¨è...")
            industry_stocks = [stock for stock in stocks_recommended if industry in stock["reason"]]
            if industry_stocks:
                stock_recommendations += f"### ğŸ“ˆ {industry}æ¿å—\n"
                industry_stock_count = 0  # æ¯ä¸ªè¡Œä¸šçš„è‚¡ç¥¨è®¡æ•°

                for stock in industry_stocks:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ¨èè¿‡è¿™åªè‚¡ç¥¨
                    stock_code = stock.get('code', '')
                    if stock_code in used_stocks:
                        print(f"âš ï¸ è·³è¿‡é‡å¤è‚¡ç¥¨: {stock_code} {stock.get('name', '')}")
                        continue

                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ¯ä¸ªè¡Œä¸šçš„æœ€å¤§æ¨èæ•°é‡
                    if industry_stock_count >= 3:
                        break

                    used_stocks.add(stock_code)  # æ·»åŠ åˆ°å·²ä½¿ç”¨é›†åˆ
                    industry_stock_count += 1

                    risk_emoji = {"ä½": "ğŸŸ¢", "ä¸­": "ğŸŸ¡", "é«˜": "ğŸ”´"}.get(stock.get("risk", ""), "âšª")
                    impact_emoji = {"é«˜": "ğŸ”¥", "ä¸­": "âš¡", "ä½": "ğŸ’¡"}.get(stock.get("impact", "ä¸­"), "ğŸ’¡")
                    stock_recommendations += f"- **{stock['code']} {stock['name']}** {risk_emoji} {impact_emoji}\n"
                    stock_recommendations += f"  - æ¨èç†ç”±: {stock['reason']}\n"
                    stock_recommendations += f"  - é£é™©ç­‰çº§: {stock['risk']}\n"
                    if stock.get("impact"):
                        stock_recommendations += f"  - å½±å“ç¨‹åº¦: {stock['impact']}\n"

                    # è·å–å®æ—¶æ•°æ®
                    try:
                        print(f"ğŸ“Š æ­£åœ¨è·å–{stock['code']}çš„å®æ—¶æ•°æ®...")
                        real_time_data = get_real_time_stock_data(stock['code'])

                        if real_time_data:
                            # å®æ—¶ä»·æ ¼å’Œæ¶¨è·Œå¹…
                            price_change_emoji = "ğŸ“ˆ" if real_time_data["price_change"] > 0 else "ğŸ“‰" if real_time_data["price_change"] < 0 else "â¡ï¸"
                            stock_recommendations += f"  - **å®æ—¶ä»·æ ¼**: Â¥{real_time_data['current_price']} {price_change_emoji} {real_time_data['price_change']}%\n"

                            # åŸºæœ¬é¢æ•°æ®
                            if real_time_data["pe_ratio"] != 'N/A' and real_time_data["pe_ratio"] is not None:
                                pe_str = f"{real_time_data['pe_ratio']:.1f}" if isinstance(real_time_data['pe_ratio'], (int, float)) else str(real_time_data['pe_ratio'])
                                pb_str = f"{real_time_data['pb_ratio']:.2f}" if real_time_data['pb_ratio'] != 'N/A' and real_time_data['pb_ratio'] is not None and isinstance(real_time_data['pb_ratio'], (int, float)) else 'N/A'
                                stock_recommendations += f"  - **ä¼°å€¼**: PE{pe_str} | PB{pb_str}\n"

                            # æŠ€æœ¯é¢åˆ†æ
                            trend = "ä¸Šæ¶¨" if real_time_data["current_price"] > real_time_data["ma20"] else "ä¸‹è·Œ" if real_time_data["current_price"] < real_time_data["ma20"] else "éœ‡è¡"
                            stock_recommendations += f"  - **æŠ€æœ¯é¢**: {trend} | MA20:Â¥{real_time_data['ma20']:.2f} | MA50:Â¥{real_time_data['ma50']:.2f}\n"

                            # æ”¯æ’‘é˜»åŠ›ä½
                            stock_recommendations += f"  - **æ”¯æ’‘/é˜»åŠ›**: Â¥{real_time_data['recent_low']:.2f} / Â¥{real_time_data['recent_high']:.2f}\n"

                            # æˆäº¤é‡åˆ†æ
                            volume_emoji = "ğŸ”¥" if real_time_data["volume_ratio"] > 1.5 else "ğŸ“Š" if real_time_data["volume_ratio"] > 1 else "ğŸ“‰"
                            stock_recommendations += f"  - **æˆäº¤é‡**: {volume_emoji} {real_time_data['volume_ratio']:.1f}å€\n"

                            # äº¤æ˜“å»ºè®®ï¼ˆåŸºäºå®æ—¶æ•°æ®ï¼‰
                            entry_price = real_time_data["current_price"] * 0.95  # å»ºè®®åœ¨ç°ä»·5%ä»¥ä¸‹ä¹°å…¥
                            stop_loss = real_time_data["current_price"] * 0.92    # æ­¢æŸè®¾åœ¨ç°ä»·8%ä»¥ä¸‹
                            target_price = real_time_data["current_price"] * 1.15  # ç›®æ ‡ä»·è®¾åœ¨ç°ä»·15%ä»¥ä¸Š

                            stock_recommendations += f"  - **ä¹°å…¥å»ºè®®**: Â¥{entry_price:.2f}ä»¥ä¸‹\n"
                            stock_recommendations += f"  - **æ­¢æŸä½**: Â¥{stop_loss:.2f}\n"
                            stock_recommendations += f"  - **ç›®æ ‡ä»·**: Â¥{target_price:.2f}\n"
                        else:
                            stock_recommendations += f"  - **æ•°æ®è·å–å¤±è´¥**ï¼Œè¯·æ‰‹åŠ¨æŸ¥è¯¢\n"
                    except Exception as e:
                        print(f"âš ï¸ å¤„ç†{stock['code']}æ•°æ®æ—¶å‡ºé”™: {e}")
                        stock_recommendations += f"  - **æ•°æ®å¤„ç†é”™è¯¯**ï¼Œè¯·æ‰‹åŠ¨æŸ¥è¯¢\n"

                    stock_recommendations += "\n"
        stock_recommendations += "âš ï¸ **æŠ•èµ„æé†’**: ä»¥ä¸Šæ¨èåŸºäºä»Šæ—¥æ–°é—»åŠ¨æ€ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ï¼\n\n"

        # æ·»åŠ æŠ•èµ„ç­–ç•¥å»ºè®®
        strategy_section = "## ğŸ’¡ æŠ•èµ„ç­–ç•¥å»ºè®®\n\n"
        strategy_section += "### ğŸ“ˆ å»ºä»“ç­–ç•¥\n"
        strategy_section += "- **åˆ†æ‰¹å»ºä»“**: å»ºè®®åˆ†3-5æ¬¡é€æ­¥å»ºä»“ï¼Œé™ä½å•æ¬¡é£é™©\n"
        strategy_section += "- **ä»“ä½æ§åˆ¶**: å•åªè‚¡ç¥¨ä¸è¶…è¿‡æ€»ä»“ä½çš„10-15%\n"
        strategy_section += "- **æ—¶æœºæŠŠæ¡**: å…³æ³¨å›è°ƒæœºä¼šï¼Œé¿å…è¿½é«˜\n\n"

        strategy_section += "### ğŸ›¡ï¸ é£é™©æ§åˆ¶\n"
        strategy_section += "- **æ­¢æŸè®¾ç½®**: ä¸¥æ ¼æ‰§è¡Œæ­¢æŸï¼Œä¸€èˆ¬ä¸è¶…è¿‡-8%\n"
        strategy_section += "- **æ­¢ç›ˆç­–ç•¥**: åˆ†æ‰¹æ­¢ç›ˆï¼Œé”å®šéƒ¨åˆ†åˆ©æ¶¦\n"
        strategy_section += "- **åˆ†æ•£æŠ•èµ„**: é¿å…è¿‡åº¦é›†ä¸­åœ¨å•ä¸€è¡Œä¸š\n\n"

        strategy_section += "### ğŸ“Š æŒä»“ç®¡ç†\n"
        strategy_section += "- **å®šæœŸæ£€è§†**: æ¯å‘¨è¯„ä¼°æŒä»“è¡¨ç°\n"
        strategy_section += "- **åŠ¨æ€è°ƒæ•´**: æ ¹æ®å¸‚åœºå˜åŒ–è°ƒæ•´ä»“ä½\n"
        strategy_section += "- **é•¿æœŸæ€ç»´**: ä¼˜è´¨è‚¡ç¥¨å¯é•¿æœŸæŒæœ‰\n\n"

        stock_recommendations += strategy_section

    # ç”Ÿæˆä»…å±•ç¤ºæ ‡é¢˜å’Œé“¾æ¥çš„æœ€ç»ˆæ¶ˆæ¯
    final_summary = f"ğŸ“… **{today_str} è´¢ç»æ–°é—»æ‘˜è¦**\n\n{sentiment_section}{indices_section}{timing_section}{global_analysis}âœï¸ **ä»Šæ—¥åˆ†ææ€»ç»“ï¼š**\n{summary}\n\n{stock_recommendations}---\n\n"
    for category, content in articles_data.items():
        if content.strip():
            final_summary += f"## {category}\n{content}\n\n"

    # æ¨é€åˆ°å¤šä¸ªserveré…±key
    # send_to_wechat(title=f"ğŸ“Œ {today_str} è´¢ç»æ–°é—»æ‘˜è¦", content=final_summary)
    send_email_notification(
        title=f"ğŸ¯ {today_str} çŸ­çº¿äº¤æ˜“åˆ†æ", 
        content=final_summary
    )
